from time import sleep
import re
import requests
from bs4 import BeautifulSoup
from requests_html import HTMLSession
import pandas as pd

url = "https://onsen.nifty.com/ip-konzatsu/"
base_url = "https://onsen.nifty.com"

r = requests.get(url, timeout=3)
sleep(2)
r.raise_for_status()
soup = BeautifulSoup(r.content, "lxml")

#æ··é›‘çŠ¶æ³ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºã«åŠ ç›Ÿã—ã¦ã„ã‚‹æ–½è¨­æƒ…å ±ã‚’å…¨å–å¾—
contents = soup.find_all("div", class_="facility")
d_list = []
#å„æ¸©æ³‰æ–½è¨­ã®æƒ…å ±ã‚’å–å¾—
for i,content in enumerate(contents, start=1):
    print("="*30, i, "="*30)
    #å–å¾—ã—ãŸã„éƒ½é“åºœçœŒã‚’æŠ½å‡º
    prefectures = content.find("span", class_="areaOnecol")
    if not prefectures.find(text=re.compile("é™å²¡çœŒ|å±±æ¢¨çœŒ")):
        continue
    
    facility_name = content.find("div", class_="titleOnecol").find("a").text
    a_tag = content.find("a").get("href")
    page_url = base_url + a_tag + "#congestionInfo"
    #ã“ã®ãƒšãƒ¼ã‚¸ã¯javascriptã‚’ä½¿ç”¨ã—ãŸå‹•çš„ãªãƒšãƒ¼ã‚¸ã®ãŸã‚
    # requsts_htmlãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®HTMLSessionãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒå¿…è¦
    s = HTMLSession()
    r = s.get(page_url,timeout=3)
    #ã“ã“ã§ãƒšãƒ¼ã‚¸ã®ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
    r.html.render(timeout=20)
    print(r.status_code)
    sleep(3)
    page_session = r.html
    evaluation = page_session.find("dl.evaluation1", first=True).find("span.score", first=True).text
    outlines = page_session.find("div.outlineInner2",first=True).find("tr", first=False)
    address = outlines[2].find("td", first=True).text
    
    if outlines[4].find("th", first=True).text == "å–¶æ¥­æ™‚é–“":
        business_hour = outlines[4].find("td", first=True).text
    else:
         business_hour = "éæ²è¼‰"
    if  page_session.find("dl.dateList1", first=True):
        price = page_session.find("dl.dateList1", first=True).find("dd",first=True).text
    else:
        price = "éæ²è¼‰"

    if outlines[-1].find("th", first=True).text == "å…¬å¼HP":
        official_hp = outlines[-1].find("td", first=True).text
    else:
        official_hp = "éæ²è¼‰"

    access = page_session.find("dl.dateList2", first=True).find("dd", first=False)[0].text

    #æ··é›‘çŠ¶æ³ã®çµµã¨çµµæ–‡å­—ã®å¯¾å¿œãƒªã‚¹ãƒˆ
    number_list = {
        "/congestion/images/crowd_icon/01_not_crowd.png": "ğŸ˜„",
        "/congestion/images/crowd_icon/02_normal.png": "ğŸ˜ƒ",
        "/congestion/images/crowd_icon/03_little_crowd.png": "ğŸ˜",
        "/congestion/images/crowd_icon/04_crowd.png": "ğŸ˜°",
        "/congestion/images/crowd_icon/05_much_crowd.png": "ğŸ¥µ",
        "/congestion/images/crowd_icon/06_close.png": "å–¶æ¥­æ™‚é–“å¤–",
    }
    
    #æ··é›‘çŠ¶æ³ãƒªã‚¹ãƒˆ
    congestion_list = []
    updated_date = page_session.find("p.currentState", first=True).text
    congestions = page_session.find("div.mdl-card-height", first=False)
    for congestion in congestions:
        congested_area = congestion.find("h3.mdl-card__title-text", first=True).text
        try:
            number_of_people = congestion.find("img", first=True).attrs["src"]
            congestion_list.append({
                congested_area : number_list[number_of_people]
            })
        except:
            number_of_people = "éè¡¨ç¤º"
            congestion_list.append({
                congested_area : number_of_people
            })
        sleep(1)

    d_list.append({
        "æ–½è¨­å": facility_name,
        "ä½æ‰€": address,
        "è©•ä¾¡ (5ç‚¹æº€ç‚¹)": evaluation,
        "æ··é›‘çŠ¶æ³ (ğŸ˜„ç©ºã„ã¦ã„ã‚‹ã€ğŸ˜ƒã‚„ã‚„ç©ºã„ã¦ã„ã‚‹ã€ğŸ˜æ™®é€šã€ğŸ˜°ã‚„ã‚„æ··é›‘ã€ğŸ¥µæ··é›‘)"
        : f"{updated_date} / {congestion_list}",
        # "æ··é›‘çŠ¶æ³": f"{updated_date} / {congestion_list}",
        "å–¶æ¥­æ™‚é–“": business_hour,
        "ä¾¡æ ¼": price,
        "ã‚¢ã‚¯ã‚»ã‚¹": access,
        "å…¬å¼HP": official_hp 
    })
    sleep(1)
    print(d_list)

print(d_list)
#pandasã‚’ä½¿ã£ã¦ã€åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ã«ã™ã‚‹
df = pd.DataFrame(d_list)
#è¡¨ã‚’csvå½¢å¼ã§å‡ºåŠ›ã™ã‚‹
df.to_csv("test.csv", index=None, encoding="utf-8-sig")

